---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s-labs/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: vernemq
spec:
  interval: 30m
  chartRef:
    kind: OCIRepository
    name: app-template
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controllers:
      vernemq:
        type: statefulset
        strategy: RollingUpdate
        replicas: 2

        annotations:
          secret.reloader.stakater.com/reload: vernemq-auth-secret

        pod:
          securityContext:
            runAsUser: 10000
            runAsNonRoot: true

        containers:
          app:
            image:
              repository: vernemq/vernemq
              tag: 2.0.1-alpine@sha256:5f2ffe9ec73c4910f9c32197414bd72d0a6b31035334ff14748185797312b47f
            env:
              MY_POD_NAME:
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              DOCKER_VERNEMQ_ACCEPT_EULA: "yes"
              DOCKER_VERNEMQ_DISCOVERY_KUBERNETES: 1
              DOCKER_VERNEMQ_KUBERNETES_LABEL_SELECTOR: "app.kubernetes.io/name=vernemq"
              DOCKER_VERNEMQ_LEVELDB__WRITE_BUFFER_SIZE_MIN: "2500000"
              DOCKER_VERNEMQ_LEVELDB__WRITE_BUFFER_SIZE_MAX: "7500000"
              DOCKER_VERNEMQ_LEVELDB__MAXIMUM_MEMORY: "128000000"
              # allow clients to failover when pods are restarting
              DOCKER_VERNEMQ_ALLOW_REGISTER_DURING_NETSPLIT: "on"
              DOCKER_VERNEMQ_ALLOW_PUBLISH_DURING_NETSPLIT: "on"
              DOCKER_VERNEMQ_ALLOW_SUBSCRIBE_DURING_NETSPLIT: "on"
              DOCKER_VERNEMQ_ALLOW_UNSUBSCRIBE_DURING_NETSPLIT: "on"

            envFrom:
              - secretRef:
                  name: vernemq-auth-secret

            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health/ping
                    port: 8888
                  periodSeconds: 10
                  timeoutSeconds: 5
              readiness: *probes
              startup:
                <<: *probes
                spec:
                  exec:
                    command:
                      # vernemq immediately reports healthy, even before retained messages are replicated
                      # so we need to make sure all nodes have the same num_replicated on startup
                      # see https://github.com/vernemq/docker-vernemq/issues/255
                      - /bin/sh
                      - -c
                      - >-
                        curl -s localhost:8888/status.json |
                        jq -e '.[0] | [to_entries.[].value.num_retained] | .[0] as $x | all(.[]; . == $x)'
                  periodSeconds: 10
                  timeoutSeconds: 5
            resources:
              requests:
                cpu: 20m
                memory: 128Mi
              limits:
                memory: 512Mi
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                  - ALL

    service:
      app:
        primary: true
        type: LoadBalancer
        sessionAffinity: ClientIP
        annotations:
          external-dns.alpha.kubernetes.io/hostname: "mqtt.zinn.ca."
          lbipam.cilium.io/ips: 10.11.1.13
        ports:
          mqtt:
            port: 1883
          ws:
            port: 8080
      headless:
        publishNotReadyAddresses: true
        clusterIP: None
        ports:
          mqtt:
            port: 1883
          metrics:
            port: 8888
          ws:
            port: 8080
      metrics:
        ports:
          http:
            port: 8888

    persistence:
      data:
        type: emptyDir
        globalMounts:
          - path: /vernemq/data
      tmpfs:
        type: emptyDir
        advancedMounts:
          vernemq:
            app:
              - path: /vernemq/log
                subPath: log
              - path: /tmp
                subPath: tmp

    serviceAccount:
      vernemq: {}

    serviceMonitor:
      app:
        service:
          identifier: metrics
        endpoints:
          - port: http
            scheme: http
            path: /metrics
            interval: 10s
            scrapeTimeout: 1s

    rbac:
      roles:
        vernemq:
          type: Role
          rules:
            - apiGroups:
                - ""
              resources:
                - pods
              verbs:
                - get
                - list
            - apiGroups:
                - apps
              resources:
                - statefulsets
              verbs:
                - get
      bindings:
        vernemq:
          type: RoleBinding
          roleRef:
            identifier: vernemq
          subjects:
            - identifier: vernemq
